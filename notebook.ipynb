{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af33b82-9671-4ed7-827f-8348f744db96",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d400a6ac-fe40-4d99-bcc7-177c5633adee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Input, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8704b90b-a10f-4c22-a9f0-84a173f2c71e",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc74db2f-62d9-457f-9c8c-47bdb1e46574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is your first name?</td>\n",
       "      <td>My full name is Emuejevoke Eshemitan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could you please spell your first name for me?</td>\n",
       "      <td>My full name is Emuejevoke Eshemitan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do you have any nicknames or alternate names y...</td>\n",
       "      <td>My full name is Emuejevoke Eshemitan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do you pronounce your last name, Eshemitan?</td>\n",
       "      <td>My full name is Emuejevoke Eshemitan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Do you have any middle names?</td>\n",
       "      <td>My full name is Emuejevoke Eshemitan.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>Is there something I can do to make things eas...</td>\n",
       "      <td>I am good, thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>Do you have any specific needs I can address?</td>\n",
       "      <td>I am good, thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>Can I assist you in any way to make things bet...</td>\n",
       "      <td>I am good, thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>Do you need any advice or guidance on a partic...</td>\n",
       "      <td>I am good, thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>Is there something on your mind that you'd lik...</td>\n",
       "      <td>I am good, thank you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Questions  \\\n",
       "0                              What is your first name?   \n",
       "1        Could you please spell your first name for me?   \n",
       "2     Do you have any nicknames or alternate names y...   \n",
       "3       How do you pronounce your last name, Eshemitan?   \n",
       "4                         Do you have any middle names?   \n",
       "...                                                 ...   \n",
       "1745  Is there something I can do to make things eas...   \n",
       "1746      Do you have any specific needs I can address?   \n",
       "1747  Can I assist you in any way to make things bet...   \n",
       "1748  Do you need any advice or guidance on a partic...   \n",
       "1749  Is there something on your mind that you'd lik...   \n",
       "\n",
       "                                    Answers  \n",
       "0     My full name is Emuejevoke Eshemitan.  \n",
       "1     My full name is Emuejevoke Eshemitan.  \n",
       "2     My full name is Emuejevoke Eshemitan.  \n",
       "3     My full name is Emuejevoke Eshemitan.  \n",
       "4     My full name is Emuejevoke Eshemitan.  \n",
       "...                                     ...  \n",
       "1745                   I am good, thank you  \n",
       "1746                   I am good, thank you  \n",
       "1747                   I am good, thank you  \n",
       "1748                   I am good, thank you  \n",
       "1749                   I am good, thank you  \n",
       "\n",
       "[1750 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset from the CSV file\n",
    "data = pd.read_csv('updated.csv')\n",
    "data = data[:1750]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6709a74-0c4f-45a0-90b7-ff0995031be3",
   "metadata": {},
   "source": [
    "Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b39d25-2abd-47aa-88ae-794f3a9f18c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In which year did your story begin?</td>\n",
       "      <td>I am 24 years old.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have any favorite childhood memories wi...</td>\n",
       "      <td>I have three siblings: a younger brother (Omom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the destination that you've always had...</td>\n",
       "      <td>I would love to visit Bali and Greece someday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have any picturesque destinations on yo...</td>\n",
       "      <td>I would love to visit Bali and Greece someday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do you find relief from stress or navigate...</td>\n",
       "      <td>I relax, breathe, accept and work harder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>Do you have any pet?</td>\n",
       "      <td>I don't have any pets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>Are there any challenges or responsibilities t...</td>\n",
       "      <td>I am 24 years old.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>Are there any  activities related to pet care ...</td>\n",
       "      <td>I don't have any pets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>Are there any factor into your decision to not...</td>\n",
       "      <td>I don't have any pets.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>Do you have any brothers or just sisters?</td>\n",
       "      <td>I have three siblings: a younger brother (Omom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1750 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Questions  \\\n",
       "0                   In which year did your story begin?   \n",
       "1     Do you have any favorite childhood memories wi...   \n",
       "2     What is the destination that you've always had...   \n",
       "3     Do you have any picturesque destinations on yo...   \n",
       "4     How do you find relief from stress or navigate...   \n",
       "...                                                 ...   \n",
       "1745                               Do you have any pet?   \n",
       "1746  Are there any challenges or responsibilities t...   \n",
       "1747  Are there any  activities related to pet care ...   \n",
       "1748  Are there any factor into your decision to not...   \n",
       "1749          Do you have any brothers or just sisters?   \n",
       "\n",
       "                                                Answers  \n",
       "0                                    I am 24 years old.  \n",
       "1     I have three siblings: a younger brother (Omom...  \n",
       "2     I would love to visit Bali and Greece someday ...  \n",
       "3     I would love to visit Bali and Greece someday ...  \n",
       "4              I relax, breathe, accept and work harder  \n",
       "...                                                 ...  \n",
       "1745                             I don't have any pets.  \n",
       "1746                                 I am 24 years old.  \n",
       "1747                             I don't have any pets.  \n",
       "1748                             I don't have any pets.  \n",
       "1749  I have three siblings: a younger brother (Omom...  \n",
       "\n",
       "[1750 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the DataFrame rows\n",
    "data = data.sample(frac = 1, ignore_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa525c8-565c-4d36-8b00-004bbb9d840a",
   "metadata": {},
   "source": [
    "Check for duplicated rows in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc26a64-0ef7-4fbf-84c9-a81226faf1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2912efed-256e-4050-a45f-062bf80d3d70",
   "metadata": {},
   "source": [
    "Drop duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18a1e504-2293-44fb-ae04-0c3badf1ac21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates()\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c0f9c1-58e5-4d2a-a8f9-e461de957587",
   "metadata": {},
   "source": [
    "Get number of classes or categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e413e3c-d5ab-4922-8c4b-17ea2f9bc303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of categories\n",
    "no_cat = data['Answers'].nunique()\n",
    "no_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da594dc-be88-4ef1-af94-56de2a797ffe",
   "metadata": {},
   "source": [
    "Check if the data is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3343bc9b-a82e-40a5-bdd2-1a717199d958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    count\n",
      "Answers                                                  \n",
      "I love dark, cloudy and rainy weather.                 50\n",
      "I have three siblings: a younger brother (Omomi...     50\n",
      "I am good, thank you                                   50\n",
      "I am an easy-going and free-spirited person.           50\n",
      "I possess a strong skill set in Python programm...     50\n",
      "My Contact Information includes: Phone number: ...     50\n",
      "I feel strongly about reducing carbon emissions...     50\n",
      "My long-term personal goal outside of my career...     50\n",
      "I enjoy all genres of music depending on my moo...     50\n",
      "My birthday is february 26th                           50\n",
      "\"God Abeg\" and \"It is what it is\" are Nigerian ...     50\n",
      "I detest unclean surroundings, avoid oily food,...     50\n",
      "I am passionate about using machine learning ap...     50\n",
      "My ideal weekend involves coding and occasional...     50\n",
      "I don't have any pets.                                 50\n",
      "I am an introvert                                      50\n",
      "I speak English.                                       50\n",
      "My hobbies include coding, watching movies and ...     50\n",
      "I don't play any musical instruments. But I wou...     50\n",
      "I would love to visit Bali and Greece someday w...     50\n",
      "I relax, breathe, accept and work harder               50\n",
      "Currently I have no favorite book.                     50\n",
      "I enjoy watching comedy movies alot!.                  50\n",
      "My favorite color is Black                             50\n",
      "I love African Cuisine and my favorite meal is ...     50\n",
      "I am single                                            50\n",
      "I try to workout at least 4 times a week               50\n",
      "my phobia is \"peniaphobia\"  also known as  \"pov...     50\n",
      "I consider myself a morning person.                    50\n",
      "I am a fan of Manchester United football club          50\n",
      "I play chess!                                          49\n",
      "My full name is Emuejevoke Eshemitan.                  49\n",
      "I am 24 years old.                                     49\n",
      "I am a Data Scientist / Machine Learning Engineer.     47\n",
      "I am Nigerian, I was born and raised in Delta S...     46\n"
     ]
    }
   ],
   "source": [
    "#M class has way less data than the orthers, thus the classes are unbalanced.\n",
    "value_counts_table = pd.DataFrame(data['Answers'].value_counts())\n",
    "print(value_counts_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f421cebf-4b26-4a72-867e-650656af5d35",
   "metadata": {},
   "source": [
    "label encode target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d8a10e2-9d4c-497c-9419-6a9eb3856a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the LabelEncoder on the target\n",
    "label_encoder.fit(data['Answers'])\n",
    "\n",
    "# Perform label encoding on the target\n",
    "encoded_answers = label_encoder.transform(data['Answers'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1aee8f-1b47-4f2c-81b7-90d4556584b3",
   "metadata": {},
   "source": [
    "Save the label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e5bdbfa-090b-41d2-84d3-21c777b50b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_encoder.pickle', 'wb') as handle:\n",
    "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aa73575-53f7-40bc-8918-067bddf8ecb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "      <th>Answers</th>\n",
       "      <th>answer_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In which year did your story begin?</td>\n",
       "      <td>I am 24 years old.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have any favorite childhood memories wi...</td>\n",
       "      <td>I have three siblings: a younger brother (Omom...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the destination that you've always had...</td>\n",
       "      <td>I would love to visit Bali and Greece someday ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you have any picturesque destinations on yo...</td>\n",
       "      <td>I would love to visit Bali and Greece someday ...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do you find relief from stress or navigate...</td>\n",
       "      <td>I relax, breathe, accept and work harder</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>Do you have any pet?</td>\n",
       "      <td>I don't have any pets.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>Are there any challenges or responsibilities t...</td>\n",
       "      <td>I am 24 years old.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>Are there any  activities related to pet care ...</td>\n",
       "      <td>I don't have any pets.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>Are there any factor into your decision to not...</td>\n",
       "      <td>I don't have any pets.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>Do you have any brothers or just sisters?</td>\n",
       "      <td>I have three siblings: a younger brother (Omom...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1740 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Questions  \\\n",
       "0                   In which year did your story begin?   \n",
       "1     Do you have any favorite childhood memories wi...   \n",
       "2     What is the destination that you've always had...   \n",
       "3     Do you have any picturesque destinations on yo...   \n",
       "4     How do you find relief from stress or navigate...   \n",
       "...                                                 ...   \n",
       "1745                               Do you have any pet?   \n",
       "1746  Are there any challenges or responsibilities t...   \n",
       "1747  Are there any  activities related to pet care ...   \n",
       "1748  Are there any factor into your decision to not...   \n",
       "1749          Do you have any brothers or just sisters?   \n",
       "\n",
       "                                                Answers  answer_labels  \n",
       "0                                    I am 24 years old.              2  \n",
       "1     I have three siblings: a younger brother (Omom...             18  \n",
       "2     I would love to visit Bali and Greece someday ...             26  \n",
       "3     I would love to visit Bali and Greece someday ...             26  \n",
       "4              I relax, breathe, accept and work harder             23  \n",
       "...                                                 ...            ...  \n",
       "1745                             I don't have any pets.             13  \n",
       "1746                                 I am 24 years old.              2  \n",
       "1747                             I don't have any pets.             13  \n",
       "1748                             I don't have any pets.             13  \n",
       "1749  I have three siblings: a younger brother (Omom...             18  \n",
       "\n",
       "[1740 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add labels to dataset\n",
    "data['answer_labels'] = encoded_answers\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe071497-4d0b-4fb6-bdc1-3407de35cb63",
   "metadata": {},
   "source": [
    "One-Hot encode the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "890918e6-b357-4b60-bc26-551e6ae8e27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "encoded_labels = to_categorical(encoded_answers, num_classes=no_cat)\n",
    "print(encoded_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55042f21-9b6c-4607-bbb2-5a8208e9522e",
   "metadata": {},
   "source": [
    "Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc80f32b-3c94-42cf-bf68-e84281d6a5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2020 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "\n",
    "# Fit on predictor data (the questions data)\n",
    "tokenizer.fit_on_texts(data['Questions'].values)\n",
    "sequences = tokenizer.texts_to_sequences(data['Questions'].values) # converts sentence to vectors\n",
    "\n",
    "# Print no of unique words or tokens\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c2c313-7584-4fd6-9e60-ad7a3d2850bd",
   "metadata": {},
   "source": [
    "Save trained tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f6028f6-ec64-4d42-b03e-c24d394d7e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841dccb0-8c13-4381-a553-edf85f2aff3a",
   "metadata": {},
   "source": [
    "check the max lenght of the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1040f376-2476-44e7-99d9-1a6c32d9ae89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of sequence: 23\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(x) for x in sequences])\n",
    "print(f\"maximum length of sequence: {max_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f21d470-3e98-4c9f-9a2e-0794df32d988",
   "metadata": {},
   "source": [
    "Now we pad the sequence to have the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c28955e-d648-42f2-9c4f-bfdc488576af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(sequences, 23) # This will be the data we use to train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b36358-0c7a-49d7-98d6-b05fca0b627a",
   "metadata": {},
   "source": [
    "Split the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b67c85-11e3-4a54-b493-72705a521eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X , encoded_labels, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7299df-b336-4275-a0f8-43fc04b2ddba",
   "metadata": {},
   "source": [
    "Build The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46bc600a-5c92-4dae-8bed-4dc974c4e3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 23)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 23, 200)           404200    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 23, 64)            67840     \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 64)                0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 35)                2275      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 474315 (1.81 MB)\n",
      "Trainable params: 474315 (1.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Embedding dimensionality\n",
    "emb_dim = 200\n",
    "\n",
    "# Note we actually want the size of the embedding to be the length of the tokenizer index + 1\n",
    "emb_size = len(tokenizer.word_index) + 1 # because token starts with 1 and not 0\n",
    "\n",
    "i = Input(shape=(X.shape[1],)) # Input shape should be sequence lemgth\n",
    "x = Embedding(emb_size, emb_dim)(i)\n",
    "x = LSTM(64, dropout=0.6, return_sequences=True)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(no_cat, activation='softmax')(x)\n",
    "\n",
    "model = Model(i, x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bab84a2-b228-4959-aa97-43239edbc267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 5s 140ms/step - loss: 3.5547 - acc: 0.0345 - val_loss: 3.5494 - val_acc: 0.0575\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 1s 66ms/step - loss: 3.5422 - acc: 0.0639 - val_loss: 3.5401 - val_acc: 0.0575\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 3.5252 - acc: 0.1114 - val_loss: 3.5238 - val_acc: 0.1034\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 3.4975 - acc: 0.1767 - val_loss: 3.4956 - val_acc: 0.1523\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 3.4461 - acc: 0.2227 - val_loss: 3.4399 - val_acc: 0.1580\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 3.3314 - acc: 0.2134 - val_loss: 3.3067 - val_acc: 0.1149\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 3.1077 - acc: 0.2040 - val_loss: 3.0919 - val_acc: 0.2069\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 2.8207 - acc: 0.3297 - val_loss: 2.8453 - val_acc: 0.3218\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 2.5085 - acc: 0.4655 - val_loss: 2.6091 - val_acc: 0.3793\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 2.1867 - acc: 0.6142 - val_loss: 2.3171 - val_acc: 0.5489\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 1s 67ms/step - loss: 1.9002 - acc: 0.7371 - val_loss: 2.0693 - val_acc: 0.6523\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 1.6370 - acc: 0.8326 - val_loss: 1.8939 - val_acc: 0.6695\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 1.4219 - acc: 0.8563 - val_loss: 1.7135 - val_acc: 0.7069\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 1s 67ms/step - loss: 1.2383 - acc: 0.8930 - val_loss: 1.5660 - val_acc: 0.7328\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 1.0691 - acc: 0.9138 - val_loss: 1.4672 - val_acc: 0.7443\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 1s 88ms/step - loss: 0.9436 - acc: 0.9260 - val_loss: 1.3818 - val_acc: 0.7241\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.8269 - acc: 0.9346 - val_loss: 1.2780 - val_acc: 0.7644\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 1s 67ms/step - loss: 0.7361 - acc: 0.9447 - val_loss: 1.2734 - val_acc: 0.7443\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.6402 - acc: 0.9576 - val_loss: 1.2106 - val_acc: 0.7672\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 0.5863 - acc: 0.9598 - val_loss: 1.1213 - val_acc: 0.7615\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.5179 - acc: 0.9626 - val_loss: 1.0563 - val_acc: 0.7816\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.4549 - acc: 0.9698 - val_loss: 1.0154 - val_acc: 0.8075\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.4074 - acc: 0.9756 - val_loss: 0.9865 - val_acc: 0.7902\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 0.3728 - acc: 0.9784 - val_loss: 0.9727 - val_acc: 0.8075\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 0.3441 - acc: 0.9835 - val_loss: 0.9600 - val_acc: 0.7989\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.3092 - acc: 0.9820 - val_loss: 0.8993 - val_acc: 0.8305\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.2792 - acc: 0.9856 - val_loss: 0.9400 - val_acc: 0.7931\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 0.2521 - acc: 0.9864 - val_loss: 0.8637 - val_acc: 0.8190\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 1s 65ms/step - loss: 0.2430 - acc: 0.9885 - val_loss: 0.8701 - val_acc: 0.8190\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.2188 - acc: 0.9878 - val_loss: 0.9028 - val_acc: 0.8132\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 0.2021 - acc: 0.9892 - val_loss: 0.8276 - val_acc: 0.8218\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 0.1842 - acc: 0.9921 - val_loss: 0.8618 - val_acc: 0.8276\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.1715 - acc: 0.9943 - val_loss: 0.8252 - val_acc: 0.8190\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.1667 - acc: 0.9928 - val_loss: 0.8199 - val_acc: 0.8132\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 0.1484 - acc: 0.9957 - val_loss: 0.8341 - val_acc: 0.8075\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 0.1385 - acc: 0.9957 - val_loss: 0.8387 - val_acc: 0.8103\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.1327 - acc: 0.9957 - val_loss: 0.8203 - val_acc: 0.8132\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.1266 - acc: 0.9950 - val_loss: 0.8308 - val_acc: 0.8103\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 0.1175 - acc: 0.9964 - val_loss: 0.7747 - val_acc: 0.8161\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 0.1099 - acc: 0.9950 - val_loss: 0.8111 - val_acc: 0.8161\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.1002 - acc: 0.9986 - val_loss: 0.8302 - val_acc: 0.8132\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 0.0997 - acc: 0.9964 - val_loss: 0.7941 - val_acc: 0.8103\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.1029 - acc: 0.9957 - val_loss: 0.9111 - val_acc: 0.7874\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.0945 - acc: 0.9964 - val_loss: 0.8790 - val_acc: 0.8046\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 0.0838 - acc: 0.9957 - val_loss: 0.8456 - val_acc: 0.8075\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 0.0785 - acc: 0.9964 - val_loss: 0.8035 - val_acc: 0.8161\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 0.0739 - acc: 0.9971 - val_loss: 0.8295 - val_acc: 0.8075\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.0732 - acc: 0.9964 - val_loss: 0.8047 - val_acc: 0.8190\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.0661 - acc: 0.9978 - val_loss: 0.7683 - val_acc: 0.8190\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 0.0624 - acc: 0.9993 - val_loss: 0.8156 - val_acc: 0.8075\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0636 - acc: 0.9971 - val_loss: 0.8841 - val_acc: 0.8132\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.0572 - acc: 0.9993 - val_loss: 0.8392 - val_acc: 0.8132\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 0.0562 - acc: 0.9986 - val_loss: 0.8290 - val_acc: 0.8017\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 0.0562 - acc: 0.9978 - val_loss: 0.7881 - val_acc: 0.8190\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.0539 - acc: 0.9978 - val_loss: 0.8112 - val_acc: 0.8218\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 0.0470 - acc: 1.0000 - val_loss: 0.8440 - val_acc: 0.8075\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 0.0446 - acc: 0.9993 - val_loss: 0.8170 - val_acc: 0.8132\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.0428 - acc: 1.0000 - val_loss: 0.7951 - val_acc: 0.8161\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.0410 - acc: 1.0000 - val_loss: 0.8457 - val_acc: 0.8161\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.0404 - acc: 0.9986 - val_loss: 0.8211 - val_acc: 0.8190\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.0412 - acc: 0.9986 - val_loss: 0.8289 - val_acc: 0.8161\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.0375 - acc: 0.9993 - val_loss: 0.8173 - val_acc: 0.8103\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 1s 94ms/step - loss: 0.0368 - acc: 1.0000 - val_loss: 0.8439 - val_acc: 0.8132\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 0.0361 - acc: 0.9978 - val_loss: 0.8005 - val_acc: 0.8190\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.0347 - acc: 1.0000 - val_loss: 0.7758 - val_acc: 0.8276\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.0341 - acc: 0.9993 - val_loss: 0.7994 - val_acc: 0.8247\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 1s 89ms/step - loss: 0.0320 - acc: 0.9978 - val_loss: 0.7840 - val_acc: 0.8247\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.0334 - acc: 0.9986 - val_loss: 0.8438 - val_acc: 0.8075\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 1s 125ms/step - loss: 0.0291 - acc: 1.0000 - val_loss: 0.8192 - val_acc: 0.8132\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.0295 - acc: 1.0000 - val_loss: 0.8677 - val_acc: 0.8103\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.0270 - acc: 1.0000 - val_loss: 0.8480 - val_acc: 0.8075\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 0.0266 - acc: 1.0000 - val_loss: 0.8571 - val_acc: 0.8161\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 1s 70ms/step - loss: 0.0258 - acc: 0.9993 - val_loss: 0.8457 - val_acc: 0.8103\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 0.0250 - acc: 0.9993 - val_loss: 0.8485 - val_acc: 0.8161\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 0.0255 - acc: 1.0000 - val_loss: 0.8683 - val_acc: 0.8017\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 0.8079 - val_acc: 0.8276\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.0228 - acc: 0.9993 - val_loss: 0.8537 - val_acc: 0.8075\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.0220 - acc: 1.0000 - val_loss: 0.8496 - val_acc: 0.8161\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 1s 89ms/step - loss: 0.0200 - acc: 1.0000 - val_loss: 0.8609 - val_acc: 0.8075\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 0.0227 - acc: 0.9993 - val_loss: 0.8758 - val_acc: 0.8075\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.0207 - acc: 1.0000 - val_loss: 0.8782 - val_acc: 0.8103\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 0.0223 - acc: 0.9993 - val_loss: 0.8885 - val_acc: 0.8103\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.0204 - acc: 0.9993 - val_loss: 0.8807 - val_acc: 0.8161\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 1s 75ms/step - loss: 0.0222 - acc: 0.9986 - val_loss: 0.7750 - val_acc: 0.8362\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 1s 77ms/step - loss: 0.0217 - acc: 0.9986 - val_loss: 0.8448 - val_acc: 0.8190\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.0230 - acc: 0.9978 - val_loss: 0.8326 - val_acc: 0.8218\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 1s 108ms/step - loss: 0.0194 - acc: 1.0000 - val_loss: 0.8428 - val_acc: 0.8190\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 1s 94ms/step - loss: 0.0180 - acc: 1.0000 - val_loss: 0.8981 - val_acc: 0.8017\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 1s 81ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 0.9292 - val_acc: 0.7989\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 1s 74ms/step - loss: 0.0166 - acc: 1.0000 - val_loss: 0.8774 - val_acc: 0.8132\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 1s 90ms/step - loss: 0.0148 - acc: 1.0000 - val_loss: 0.8832 - val_acc: 0.8103\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 1s 92ms/step - loss: 0.0150 - acc: 1.0000 - val_loss: 0.8458 - val_acc: 0.8132\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 0.8430 - val_acc: 0.8305\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 1s 86ms/step - loss: 0.0143 - acc: 0.9993 - val_loss: 0.8706 - val_acc: 0.8247\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 0.8480 - val_acc: 0.8218\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.0140 - acc: 0.9993 - val_loss: 0.8566 - val_acc: 0.8075\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.8942 - val_acc: 0.8075\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 0.8657 - val_acc: 0.8247\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 0.8620 - val_acc: 0.8218\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.8652 - val_acc: 0.8276\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train, epochs=100,\n",
    "                    batch_size = 128,\n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df314151-45ab-4bcb-82b7-99bd1893a70f",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27c6ffbd-1b0b-48f8-8118-0044136bbcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a11339-c854-48b0-ab0f-70891c3361ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8169adfd-28e1-4968-bc4f-233645aeebcf",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f027e2-bdab-49cb-b48c-9ad9f69b054a",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a700273-4af4-474f-b764-eac84ebffb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "\n",
    "max_len = 23  # max length of the sequence used to train te model is 23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e31ff84-85b5-43d3-86aa-7a89146c2e6c",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bc29106-9374-4ef9-828d-a066217ff142",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3083758-2d7e-47bb-95cf-d00fa73b91e9",
   "metadata": {},
   "source": [
    "Load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3fc174d-298f-4cc4-ac5f-f4a2fb8259fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'rb') as t_handle:\n",
    "    tokenizer = pickle.load(t_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d98ed3-10cb-4062-9561-2cf1aa96cbeb",
   "metadata": {},
   "source": [
    "Load the label encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "955df976-d76b-4dcf-8b3b-17091cd5ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('label_encoder.pickle', 'rb') as l_handle:\n",
    "    label_encoder = pickle.load(l_handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e950789-c5be-4d2b-86f5-84155d039d40",
   "metadata": {},
   "source": [
    "Load the rephrase JSON file and convert it to a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46daacd4-108f-4885-b6ac-0f7a934c489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dict_phrases.json', 'r') as file:\n",
    "    dict_rephrase = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a20faa1-2f5b-4909-be58-9916816e1aa7",
   "metadata": {},
   "source": [
    "Collect user input and process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b2a6c6-638b-4d8a-b9b6-3587888896f5",
   "metadata": {},
   "source": [
    "Generate prediction and rephrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a531524-0eb6-4dbd-bcda-f64d384522a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a question:  how old are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 541ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I have just entered the age of 24 and look forward to the experiences it will bring'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare user input\n",
    "user_input = input(\"Enter a question: \")\n",
    "\n",
    "# Tokenize and pad the user input\n",
    "user_sequence = tokenizer.texts_to_sequences([user_input])\n",
    "user_X = pad_sequences(user_sequence, maxlen=max_len)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(user_X)\n",
    "\n",
    "# Decode the prediction\n",
    "decoded_prediction = label_encoder.inverse_transform(np.argmax(prediction, axis=1))\n",
    "\n",
    "key = decoded_prediction[0]\n",
    "random.choice(dict_rephrase[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359650a4-8e92-4e12-ad41-f3dc0a9edb93",
   "metadata": {},
   "source": [
    "Generate original prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f40d132f-187a-4dcb-894d-974dadb045c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a question:  who are you\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "Question: who are you\n",
      "Prediction: I am Nigerian, I was born and raised in Delta State.\n"
     ]
    }
   ],
   "source": [
    "# Prepare user input\n",
    "user_input = input(\"Enter a question: \")\n",
    "\n",
    "# Tokenize and pad the user input\n",
    "user_sequence = tokenizer.texts_to_sequences([user_input])\n",
    "user_X = pad_sequences(user_sequence, maxlen=max_len)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(user_X)\n",
    "\n",
    "# Decode the prediction\n",
    "decoded_prediction = label_encoder.inverse_transform(np.argmax(prediction, axis=1))\n",
    "\n",
    "# Print the question\n",
    "print('Question:', user_input)\n",
    "\n",
    "# Print the prediction\n",
    "print('Prediction:', decoded_prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63e68a-33bd-40fc-9d4d-7c6962478839",
   "metadata": {},
   "source": [
    "Generate all predictions with their probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63d842b3-a1f2-47c1-8fb4-8a4ab73e68ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a question:  what is your name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "1. Class: My full name is Emuejevoke Eshemitan.  Probability: 0.9519\n",
      "2. Class: I am Nigerian, I was born and raised in Delta State.  Probability: 0.0189\n",
      "3. Class: I am a Data Scientist / Machine Learning Engineer.  Probability: 0.0048\n",
      "4. Class: I am single  Probability: 0.0045\n",
      "5. Class: my phobia is \"peniaphobia\"  also known as  \"poverty phobia\".  Probability: 0.0036\n",
      "6. Class: My Contact Information includes: Phone number: +2349024362357, Email: eshemitanvoke@gmail.com, website: https://github.com/Davidsonity  Probability: 0.0027\n",
      "7. Class: I am 24 years old.  Probability: 0.0024\n",
      "8. Class: I am good, thank you  Probability: 0.0022\n",
      "9. Class: I possess a strong skill set in Python programming, SQL, machine learning, data processing, TensorFlow, scikit-learn, mathematics, effective communication, Git/GitHub, deep learning, recommendation systems and Google Cloud Platform (GCP).  Probability: 0.0014\n",
      "10. Class: I don't have any pets.  Probability: 0.0012\n",
      "11. Class: I enjoy all genres of music depending on my mood and my favorite artist currently is Rema  Probability: 0.0010\n",
      "12. Class: My hobbies include coding, watching movies and exercising  Probability: 0.0009\n",
      "13. Class: I try to workout at least 4 times a week  Probability: 0.0006\n",
      "14. Class: Currently I have no favorite book.  Probability: 0.0005\n",
      "15. Class: I play chess!  Probability: 0.0004\n",
      "16. Class: I would love to visit Bali and Greece someday with the LOML.  Probability: 0.0004\n",
      "17. Class: I am passionate about using machine learning approach to solve real-world problem  Probability: 0.0003\n",
      "18. Class: I relax, breathe, accept and work harder  Probability: 0.0003\n",
      "19. Class: I don't play any musical instruments. But I would love to learn how to play a guitar  Probability: 0.0003\n",
      "20. Class: I am an easy-going and free-spirited person.  Probability: 0.0002\n",
      "21. Class: \"God Abeg\" and \"It is what it is\" are Nigerian quotes that inspire me.  Probability: 0.0002\n",
      "22. Class: I detest unclean surroundings, avoid oily food, and crave personal space to avoid irritation.  Probability: 0.0002\n",
      "23. Class: I love dark, cloudy and rainy weather.  Probability: 0.0002\n",
      "24. Class: I am an introvert  Probability: 0.0001\n",
      "25. Class: I have three siblings: a younger brother (Omomine), an elder sister (Omeyoma) and the eldest sister (Ziregbe)  Probability: 0.0001\n",
      "26. Class: My birthday is february 26th  Probability: 0.0001\n",
      "27. Class: My long-term personal goal outside of my career is to be wealthy.  Probability: 0.0001\n",
      "28. Class: I am a fan of Manchester United football club  Probability: 0.0001\n",
      "29. Class: I speak English.  Probability: 0.0001\n",
      "30. Class: My ideal weekend involves coding and occasionally hanging out with friends.  Probability: 0.0001\n",
      "31. Class: I enjoy watching comedy movies alot!.  Probability: 0.0001\n",
      "32. Class: I consider myself a morning person.  Probability: 0.0000\n",
      "33. Class: I love African Cuisine and my favorite meal is starch and banga  Probability: 0.0000\n",
      "34. Class: My favorite color is Black  Probability: 0.0000\n",
      "35. Class: I feel strongly about reducing carbon emissions and conserving the environment.  Probability: 0.0000\n",
      "Question: what is your name\n",
      "Predicted Answers:\n",
      "My full name is Emuejevoke Eshemitan.\n",
      "I am Nigerian, I was born and raised in Delta State.\n"
     ]
    }
   ],
   "source": [
    "# Prepare user input\n",
    "user_input = input(\"Enter a question: \")\n",
    "\n",
    "# Tokenize and pad the user input\n",
    "user_sequence = tokenizer.texts_to_sequences([user_input])\n",
    "user_X = pad_sequences(user_sequence, maxlen=max_len)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(user_X)\n",
    "\n",
    "# Get the probabilities for each class\n",
    "class_probabilities = prediction[0]\n",
    "\n",
    "# Sort the probabilities in descending order\n",
    "sorted_indices = np.argsort(class_probabilities)[::-1]\n",
    "sorted_probabilities = class_probabilities[sorted_indices]\n",
    "\n",
    "# Print the sorted class probabilities\n",
    "for i, (class_index, probability) in enumerate(zip(sorted_indices, sorted_probabilities), 1):\n",
    "    class_label = label_encoder.inverse_transform([class_index])[0]\n",
    "    print(f'{i}. Class: {class_label}  Probability: {probability:.4f}')\n",
    "\n",
    "# Get the two most probable answers\n",
    "top_indices = np.argsort(prediction, axis=1)[0, -2:][::-1]\n",
    "top_answers = label_encoder.inverse_transform(top_indices)\n",
    "\n",
    "# Print the predictions\n",
    "print('Question:', user_input)\n",
    "print('Predicted Answers:')\n",
    "for answer in top_answers:\n",
    "    print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
